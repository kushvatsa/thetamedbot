{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset is taken from the ISIC (International Skin Image Collaboration) Archive. It consists of 1800 pictures of benign moles and 1497 pictures of malignant classified moles. The pictures have all been resized to low resolution (224x224x3) RGB. The task of this kernel is to create a model, which can classify a mole visually into benign and malignant. \n",
    "\n",
    "As the dataset is pretty balanced, the model will be tested on the accuracy score, thus (TP + TN)/(ALL).\n",
    "\n",
    "It has 2 different classes of skin cancer which are listed below :<br>\n",
    "**1. Benign <br>**\n",
    "**2. Malignant <br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(11) \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras import backend as K \n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Loading Data and Creating Dataset\n",
    "loading images in the pictures and turn them into numpy arrays using their RGB values. Image size 224*224\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2637 [00:00<00:12, 205.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 2637\n",
      "Size of test set: 660\n",
      "1800 benign labeled samples and 1497 malignant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2637/2637 [00:10<00:00, 249.96it/s]\n",
      "100%|██████████| 660/660 [00:03<00:00, 220.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the new train set: (2109, 224, 224, 3)\n",
      "Shape of the new test set: (660, 224, 224, 3)\n",
      "Shape of the validation set: (528, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Save the file path of each image and separate them to different classes\n",
    "#\n",
    "# Labels:\n",
    "# 0 -> benign\n",
    "# 1 -> malignant\n",
    "\n",
    "train_imgs, test_imgs = [], []\n",
    "train_labels, test_labels = [], []\n",
    "\n",
    "for img_path in os.listdir('../input/data/train/benign'):\n",
    "    train_imgs.append('../input/data/train/benign/' + img_path)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for img_path in os.listdir('../input/data/train/malignant'):\n",
    "    train_imgs.append('../input/data/train/malignant/' + img_path)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "for img_path in os.listdir('../input/data/test/benign'):\n",
    "    test_imgs.append('../input/data/test/benign/' + img_path)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for img_path in os.listdir('../input/data/test/malignant'):\n",
    "    test_imgs.append('../input/data/test/malignant/' + img_path)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "train_imgs, test_imgs = np.array(train_imgs), np.array(test_imgs)\n",
    "train_labels, test_labels = np.array(train_labels), np.array(test_labels)\n",
    "    \n",
    "class_distribution = np.bincount(np.concatenate([train_labels, test_labels]))\n",
    "    \n",
    "print('Size of train set:', len(train_imgs))\n",
    "print('Size of test set:', len(test_imgs))\n",
    "print(class_distribution[0], 'benign labeled samples and', class_distribution[1], 'malignant')\n",
    "\n",
    "# Load the images to memory\n",
    "xtrain, xtest = [], []\n",
    "ytrain, ytest = train_labels, test_labels\n",
    "\n",
    "for filename in tqdm.tqdm(train_imgs):\n",
    "    xtrain.append(np.array(Image.open(filename)))\n",
    "    \n",
    "for filename in tqdm.tqdm(test_imgs):\n",
    "    xtest.append(np.array(Image.open(filename)))\n",
    "    \n",
    "del train_imgs, test_imgs, train_labels, test_labels\n",
    "xtrain, xtest = np.array(xtrain), np.array(xtest)\n",
    "\n",
    "# Merge and split train and test set to have more train data\n",
    "data = np.concatenate([xtrain, xtest])\n",
    "labels = np.concatenate([ytrain, ytest])\n",
    "\n",
    "labels=to_categorical(labels,num_classes=2)\n",
    "\n",
    "# Spliting data to train, validation and test values\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data, labels, test_size=.2, random_state=0)\n",
    "xtra, xval, ytra, yval = train_test_split(xtrain, ytrain, test_size=.2, random_state=0, shuffle=False)\n",
    "\n",
    "gc.collect()\n",
    "print('Shape of the new train set:', xtra.shape)\n",
    "print('Shape of the new test set:', xtest.shape)\n",
    "print('Shape of the validation set:', xval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of training samples: 4218\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(rotation_range=90,\n",
    "                                    width_shift_range=0.15,\n",
    "                                    height_shift_range=0.15,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    brightness_range=[0.8, 1.1],\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "new_samples, new_labels = next(data_generator.flow(xtra, ytra, batch_size=len(xtra)))\n",
    "xtra = np.concatenate([xtra, new_samples])\n",
    "ytra = np.concatenate([ytra, new_labels])\n",
    "\n",
    "del new_samples, new_labels\n",
    "print('New number of training samples:', len(xtra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4218, 224, 224, 3)\n",
      "Min value: 0.0\n",
      "Max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalizing values\n",
    "xtra = xtra.astype('float32') / 255.\n",
    "xtest = xtest.astype('float32') / 255.\n",
    "xval = xval.astype('float32') / 255.\n",
    "\n",
    "print('Training data shape:', xtra.shape)\n",
    "print('Min value:', xtra.min())\n",
    "print('Max value:', xtra.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape= (224,224,3), lr = 1e-3, num_classes= 2,\n",
    "          init= 'normal', activ= 'relu', optim= 'adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',input_shape=input_shape,\n",
    "                     activation= activ, kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same', \n",
    "                     activation =activ, kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    if optim == 'rmsprop':\n",
    "        optimizer = RMSprop(lr=lr)\n",
    "\n",
    "    else:\n",
    "        optimizer = Adam(lr=lr)\n",
    "\n",
    "    model.compile(optimizer = optimizer ,loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=1e-7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               25690240  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 25,729,218\n",
      "Trainable params: 25,729,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4218 samples, validate on 528 samples\n",
      "Epoch 1/50\n",
      "4218/4218 [==============================] - 12s 3ms/step - loss: 1.6567 - acc: 0.5111 - val_loss: 1.1317 - val_acc: 0.5379\n",
      "Epoch 2/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 1.1993 - acc: 0.5538 - val_loss: 0.9920 - val_acc: 0.5379\n",
      "Epoch 3/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 1.0041 - acc: 0.5851 - val_loss: 1.0270 - val_acc: 0.5360\n",
      "Epoch 4/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.8810 - acc: 0.6019 - val_loss: 0.7534 - val_acc: 0.5417\n",
      "Epoch 5/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.8243 - acc: 0.6200 - val_loss: 0.8251 - val_acc: 0.5398\n",
      "Epoch 6/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.7920 - acc: 0.6086 - val_loss: 0.7219 - val_acc: 0.5473\n",
      "Epoch 7/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.7348 - acc: 0.6264 - val_loss: 0.6514 - val_acc: 0.5777\n",
      "Epoch 8/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.7095 - acc: 0.6439 - val_loss: 0.6760 - val_acc: 0.5606\n",
      "Epoch 9/50\n",
      "4218/4218 [==============================] - 11s 2ms/step - loss: 0.6834 - acc: 0.6560 - val_loss: 0.6108 - val_acc: 0.6174\n",
      "Epoch 10/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.6630 - acc: 0.6633 - val_loss: 0.6025 - val_acc: 0.6326\n",
      "Epoch 11/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.6495 - acc: 0.6683 - val_loss: 0.5749 - val_acc: 0.6439\n",
      "Epoch 12/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.6445 - acc: 0.6681 - val_loss: 0.6032 - val_acc: 0.6364\n",
      "Epoch 13/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.6285 - acc: 0.6835 - val_loss: 0.5789 - val_acc: 0.6439\n",
      "Epoch 14/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.6017 - acc: 0.6982 - val_loss: 0.5648 - val_acc: 0.6534\n",
      "Epoch 15/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5949 - acc: 0.7041 - val_loss: 0.5518 - val_acc: 0.6629\n",
      "Epoch 16/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5861 - acc: 0.7141 - val_loss: 0.5463 - val_acc: 0.6723\n",
      "Epoch 17/50\n",
      "4218/4218 [==============================] - 11s 2ms/step - loss: 0.5992 - acc: 0.7018 - val_loss: 0.5416 - val_acc: 0.6705\n",
      "Epoch 18/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5547 - acc: 0.7181 - val_loss: 0.5334 - val_acc: 0.6686\n",
      "Epoch 19/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5873 - acc: 0.7101 - val_loss: 0.5170 - val_acc: 0.6818\n",
      "Epoch 20/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.5620 - acc: 0.7259 - val_loss: 0.4973 - val_acc: 0.7027\n",
      "Epoch 21/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5532 - acc: 0.7236 - val_loss: 0.5137 - val_acc: 0.6799\n",
      "Epoch 22/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5598 - acc: 0.7229 - val_loss: 0.4965 - val_acc: 0.6989\n",
      "Epoch 23/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.5407 - acc: 0.7304 - val_loss: 0.5030 - val_acc: 0.6856\n",
      "Epoch 24/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5336 - acc: 0.7316 - val_loss: 0.4976 - val_acc: 0.6989\n",
      "Epoch 25/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5291 - acc: 0.7368 - val_loss: 0.5042 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 26/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.5154 - acc: 0.7342 - val_loss: 0.5254 - val_acc: 0.6723\n",
      "Epoch 27/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5064 - acc: 0.7454 - val_loss: 0.5085 - val_acc: 0.6856\n",
      "Epoch 28/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5132 - acc: 0.7409 - val_loss: 0.5225 - val_acc: 0.6799\n",
      "Epoch 29/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.5039 - acc: 0.7440 - val_loss: 0.5219 - val_acc: 0.6761\n",
      "Epoch 30/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.5011 - acc: 0.7480 - val_loss: 0.5158 - val_acc: 0.6799\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Epoch 31/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4973 - acc: 0.7430 - val_loss: 0.5048 - val_acc: 0.6875\n",
      "Epoch 32/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.5002 - acc: 0.7470 - val_loss: 0.5069 - val_acc: 0.6856\n",
      "Epoch 33/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4991 - acc: 0.7466 - val_loss: 0.5093 - val_acc: 0.6818\n",
      "Epoch 34/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4930 - acc: 0.7504 - val_loss: 0.5074 - val_acc: 0.6818\n",
      "Epoch 35/50\n",
      "4218/4218 [==============================] - 11s 2ms/step - loss: 0.4984 - acc: 0.7468 - val_loss: 0.5090 - val_acc: 0.6818\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 36/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4937 - acc: 0.7551 - val_loss: 0.5132 - val_acc: 0.6799\n",
      "Epoch 37/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.4952 - acc: 0.7492 - val_loss: 0.5041 - val_acc: 0.6856\n",
      "Epoch 38/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.5001 - acc: 0.7376 - val_loss: 0.5010 - val_acc: 0.6894\n",
      "Epoch 39/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4890 - acc: 0.7546 - val_loss: 0.5054 - val_acc: 0.6780\n",
      "Epoch 40/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4966 - acc: 0.7515 - val_loss: 0.5037 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 41/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4941 - acc: 0.7504 - val_loss: 0.5007 - val_acc: 0.6894\n",
      "Epoch 42/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.4921 - acc: 0.7513 - val_loss: 0.5022 - val_acc: 0.6894\n",
      "Epoch 43/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.4977 - acc: 0.7489 - val_loss: 0.5035 - val_acc: 0.6856\n",
      "Epoch 44/50\n",
      "4218/4218 [==============================] - 11s 2ms/step - loss: 0.4939 - acc: 0.7447 - val_loss: 0.5050 - val_acc: 0.6799\n",
      "Epoch 45/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4910 - acc: 0.7525 - val_loss: 0.5032 - val_acc: 0.6818\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "Epoch 46/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4961 - acc: 0.7411 - val_loss: 0.5031 - val_acc: 0.6818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4884 - acc: 0.7501 - val_loss: 0.5011 - val_acc: 0.6894\n",
      "Epoch 48/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.4878 - acc: 0.7530 - val_loss: 0.5024 - val_acc: 0.6894\n",
      "Epoch 49/50\n",
      "4218/4218 [==============================] - 11s 3ms/step - loss: 0.4907 - acc: 0.7546 - val_loss: 0.5009 - val_acc: 0.6894\n",
      "Epoch 50/50\n",
      "4218/4218 [==============================] - 10s 2ms/step - loss: 0.4889 - acc: 0.7485 - val_loss: 0.5002 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr'])\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224,3)\n",
    "lr = 1e-5\n",
    "init = 'normal'\n",
    "activ = 'relu'\n",
    "optim = 'adam'\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "model = build_model(lr=lr, init= init, activ= activ, optim=optim, input_shape= input_shape)\n",
    "\n",
    "history = model.fit(xtra, ytra, validation_data=(xval, yval),\n",
    "                    epochs= epochs, batch_size= batch_size, verbose=1, \n",
    "                    callbacks=[learning_rate_reduction],shuffle=True\n",
    "                   )\n",
    "                   \n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model on test data to evaluate\n",
    "y_pred = model.predict_classes(xtest)\n",
    "\n",
    "print(accuracy_score(np.argmax(ytest, axis=1),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN above is not a very sophisticated model, thus the resnet50, is also tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
